{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/Users/hamid/Group-06-Sentiment-Analysis-')\n",
    "sys.path.append('./scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your API Key is: AIzaSyAfhKdB3DRT9XhRCukpl64bDDHNQVJU0E8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scripts.fetch_comments import fetch_comments, save_to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2000 comments to ./Data/comments_new.csv\n",
      "Total comments fetched: 2000\n"
     ]
    }
   ],
   "source": [
    "video_id = \"JfVOs4VSpmA\"\n",
    "comments = fetch_comments(video_id,2000)\n",
    "save_to_csv(comments, \"./Data/comments_new.csv\")\n",
    "print(f\"Total comments fetched: {len(comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning_and_labeling import load_comments, filter_non_english_comments, filter_emoji_only_comments, save_cleaned_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 comments from ./Data/comments_new.csv\n",
      "Filtering non-English comments...\n",
      "Kept 1475 English comments.\n",
      "Removing emoji-only comments...\n",
      "Kept 1475 comments with text.\n",
      "Saved cleaned comments to ./Data/cleaned_comments.csv\n"
     ]
    }
   ],
   "source": [
    "input_filepath = \"./Data/comments_new.csv\"\n",
    "output_filepath = \"./Data/cleaned_comments.csv\"\n",
    "\n",
    "df = load_comments(input_filepath)\n",
    "df = filter_non_english_comments(df)\n",
    "df = filter_emoji_only_comments(df)\n",
    "save_cleaned_comments(df, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment Sentiment\n",
      "0                                 It was 3 years ago   neutral\n",
      "1  Overall it&#39;s a perfect masterpiece<br>I wa...  positive\n",
      "2  I managed to get a tenth of the way through th...  negative\n",
      "3  I still remember when this trailer was release...   neutral\n",
      "4                      Whoâ€™s here for brand new day?  positive\n",
      "Labeled comments saved to ./Data/labeled_comments.csv\n"
     ]
    }
   ],
   "source": [
    "from basic_labeling_with_TextBlob import label_comments\n",
    "\n",
    "input_filepath = \"./Data/cleaned_comments.csv\"\n",
    "output_filepath = \"./Data/labeled_comments.csv\"\n",
    "\n",
    "df = label_comments(input_filepath)\n",
    "df.to_csv(output_filepath, index=False)\n",
    "print(f\"Labeled comments saved to {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching, cleaning and labeling more negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1324 negative comments to ./Data/more_negative_comments_new.csv\n"
     ]
    }
   ],
   "source": [
    "from scripts.fetch_comments import fetch_comments\n",
    "from scripts.negative_comment_filter import filter_negative_comments\n",
    "import pandas as pd\n",
    "\n",
    "video_id = \"JfVOs4VSpmA\"\n",
    "all_comments = fetch_comments(video_id, max_results=10000)\n",
    "negative_comments = filter_negative_comments(all_comments)\n",
    "\n",
    "output_filepath = \"./Data/more_negative_comments_new.csv\"\n",
    "negative_comments.to_csv(output_filepath, index=False)\n",
    "print(f\"Saved {len(negative_comments)} negative comments to {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1327 comments from ./Data/more_negative_comments_new.csv\n",
      "Filtering non-English comments...\n",
      "Kept 1225 English comments.\n",
      "Removing emoji-only comments...\n",
      "Kept 1225 comments with text.\n",
      "Saved cleaned comments to ./Data/cleaned_negative_comments_new.csv\n",
      "Cleaned negative comments saved to ./Data/cleaned_negative_comments_new.csv\n"
     ]
    }
   ],
   "source": [
    "from cleaning_and_labeling import load_comments, filter_non_english_comments, filter_emoji_only_comments, save_cleaned_comments\n",
    "\n",
    "input_filepath = \"./Data/more_negative_comments_new.csv\" \n",
    "output_filepath = \"./Data/cleaned_negative_comments_new.csv\" \n",
    "\n",
    "df = load_comments(input_filepath)\n",
    "df = filter_non_english_comments(df)\n",
    "df = filter_emoji_only_comments(df)\n",
    "\n",
    "save_cleaned_comments(df, output_filepath)\n",
    "\n",
    "print(f\"Cleaned negative comments saved to {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching, cleaning and labeling more neutral comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1021 neutral comments to ./Data/more_neutral_comments.csv\n"
     ]
    }
   ],
   "source": [
    "from scripts.fetch_comments import fetch_comments\n",
    "from scripts.neutral_comment_filter import filter_neutral_comments\n",
    "import pandas as pd\n",
    "\n",
    "video_id = \"JfVOs4VSpmA\"\n",
    "all_comments = fetch_comments(video_id, max_results=2000)\n",
    "neutral_comments = filter_neutral_comments(all_comments)\n",
    "\n",
    "output_filepath = \"./Data/more_neutral_comments.csv\"\n",
    "neutral_comments.to_csv(output_filepath, index=False)\n",
    "print(f\"Saved {len(neutral_comments)} neutral comments to {output_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1021 comments from ./Data/more_neutral_comments.csv\n",
      "Filtering non-English comments...\n",
      "Kept 581 English comments.\n",
      "Removing emoji-only comments...\n",
      "Kept 581 comments with text.\n",
      "Saved cleaned comments to ./Data/cleaned_neutral_comments.csv\n",
      "Cleaned neutral comments saved to ./Data/cleaned_neutral_comments.csv\n"
     ]
    }
   ],
   "source": [
    "from cleaning_and_labeling import load_comments, filter_non_english_comments, filter_emoji_only_comments, save_cleaned_comments\n",
    "\n",
    "input_filepath = \"./Data/more_neutral_comments.csv\" \n",
    "output_filepath = \"./Data/cleaned_neutral_comments.csv\" \n",
    "\n",
    "df = load_comments(input_filepath)\n",
    "df = filter_non_english_comments(df)\n",
    "df = filter_emoji_only_comments(df)\n",
    "\n",
    "save_cleaned_comments(df, output_filepath)\n",
    "\n",
    "print(f\"Cleaned neutral comments saved to {output_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling cleaned dataset before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled dataset saved to ./Data/shuffled_labeled_normal.csv\n"
     ]
    }
   ],
   "source": [
    "input_filepath = \"./Data/labeled_dataset_normal.csv\" \n",
    "df = pd.read_csv(input_filepath)\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "output_filepath = \"./Data/shuffled_labeled_normal.csv\"\n",
    "df.to_csv(output_filepath, index=False)\n",
    "print(f\"Shuffled dataset saved to {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization and lemmatization complete. Saved to ./Data/tokenized_and_lemmatized_improved.csv\n"
     ]
    }
   ],
   "source": [
    "from scripts.tokenize_and_lemmatize import tokenize, lemmatize\n",
    "\n",
    "input_filepath = \"./Data/shuffled_labeled_improved.csv\"\n",
    "df = pd.read_csv(input_filepath, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# tokenization\n",
    "df[\"Tokens\"] = df[\"Comment\"].apply(tokenize)\n",
    "\n",
    "# lemmatization\n",
    "df[\"Lemmatized_Comment\"] = df[\"Tokens\"].apply(lemmatize)\n",
    "\n",
    "output_filepath = \"./Data/tokenized_and_lemmatized_improved.csv\"\n",
    "df.to_csv(output_filepath, index=False)\n",
    "print(f\"Tokenization and lemmatization complete. Saved to {output_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logestic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.73      0.77       150\n",
      "     neutral       0.73      0.77      0.75       149\n",
      "    positive       0.75      0.78      0.77       150\n",
      "\n",
      "    accuracy                           0.76       449\n",
      "   macro avg       0.76      0.76      0.76       449\n",
      "weighted avg       0.76      0.76      0.76       449\n",
      "\n",
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "input_filepath = \"./Data/tokenized_and_lemmatized_improved.csv\"\n",
    "df = pd.read_csv(input_filepath)\n",
    "\n",
    "#adjustments\n",
    "df = df.dropna()\n",
    "df = df[(df[\"Sentiment\"] != \"negetive\") & (df[\"Sentiment\"].notna())]\n",
    "\n",
    "# Featuring\n",
    "X = df[\"Lemmatized_Comment\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# Split dataset to 30% test and 70% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1500)  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(model, \"./models/logistic_regression_model.pkl\")\n",
    "joblib.dump(vectorizer, \"./models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding best C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_C = grid_search.best_params_['C']\n",
    "print(f\"Best C: {best_C}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77       150\n",
      "     neutral       0.65      0.85      0.74       149\n",
      "    positive       0.80      0.73      0.76       150\n",
      "\n",
      "    accuracy                           0.76       449\n",
      "   macro avg       0.77      0.76      0.76       449\n",
      "weighted avg       0.77      0.76      0.76       449\n",
      "\n",
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "input_filepath = \"./Data/tokenized_and_lemmatized_improved.csv\"\n",
    "df = pd.read_csv(input_filepath)\n",
    "\n",
    "#adjustments\n",
    "df = df.dropna()\n",
    "df = df[(df[\"Sentiment\"] != \"negetive\") & (df[\"Sentiment\"].notna())]\n",
    "\n",
    "X = df[\"Lemmatized_Comment\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# Split dataset into 30% test and 70% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF \n",
    "vectorizer = TfidfVectorizer(max_features=1500)  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Training\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_tfidf)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"./models/random_forest_model.pkl\")\n",
    "print(\"Model saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SVM with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.73      0.77       150\n",
      "     neutral       0.72      0.81      0.76       149\n",
      "    positive       0.78      0.77      0.78       150\n",
      "\n",
      "    accuracy                           0.77       449\n",
      "   macro avg       0.77      0.77      0.77       449\n",
      "weighted avg       0.77      0.77      0.77       449\n",
      "\n",
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#adjustments\n",
    "df = df.dropna()\n",
    "df = df[(df[\"Sentiment\"] != \"negetive\") & (df[\"Sentiment\"].notna())]\n",
    "\n",
    "X = df[\"Lemmatized_Comment\"]\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "# Split dataset into 30% test and 70% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1500)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='rbf', random_state=42)  # rbf was the best kernal among others based on accuracy\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "TF-IDF vectorizer saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "joblib.dump(svm_model, './models/svm_model.pkl')\n",
    "print(\"model saved\")\n",
    "\n",
    "joblib.dump(vectorizer, './models/tfidf_vectorizer.pkl')\n",
    "print(\"TF-IDF vectorizer saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Lexicon based analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Lexicon-Based vs. Actual Labels):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.71      0.67       500\n",
      "     neutral       0.64      0.57      0.60       496\n",
      "    positive       0.59      0.58      0.59       498\n",
      "\n",
      "    accuracy                           0.62      1494\n",
      "   macro avg       0.62      0.62      0.62      1494\n",
      "weighted avg       0.62      0.62      0.62      1494\n",
      "\n",
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "input_filepath = \"./Data/tokenized_and_lemmatized_improved.csv\"\n",
    "df = pd.read_csv(input_filepath)\n",
    "\n",
    "#adjustments\n",
    "df = df.dropna()\n",
    "df = df[(df[\"Sentiment\"] != \"negetive\") & (df[\"Sentiment\"].notna())]\n",
    "\n",
    "def lexicon_based_sentiment(text):\n",
    "   \n",
    "    sentiment_score = sa.polarity_scores(text)\n",
    "   \n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['Predicted_Sentiment_Lexicon'] = df['Lemmatized_Comment'].apply(lexicon_based_sentiment)\n",
    "\n",
    "print(\"Classification Report (Lexicon-Based vs. Actual Labels):\")\n",
    "print(classification_report(df['Sentiment'], df['Predicted_Sentiment_Lexicon']))\n",
    "accuracy = accuracy_score(df['Sentiment'], df['Predicted_Sentiment_Lexicon'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving comparison of Lexicon-Based vs. Actual Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison saved\n"
     ]
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Comment': df['Comment'],\n",
    "    'Actual_Sentiment': df['Sentiment'],\n",
    "    'Predicted_Sentiment_Lexicon': df['Predicted_Sentiment_Lexicon']\n",
    "})\n",
    "\n",
    "output_filepath = \"./Data/sentiment_comparison_improved.csv\"\n",
    "comparison_df.to_csv(output_filepath, index=False)\n",
    "print(\"Comparison saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a comment here:  we dont have better than this\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Sentiment Analysis Predictions:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Prediction: negative\n",
      "Random Forest Prediction: positive\n",
      "Logistic Regression Prediction: positive\n",
      "VADER Prediction: negative\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "svm_model = joblib.load('./models/svm_model.pkl')\n",
    "random_forest_model = joblib.load('./models/random_forest_model.pkl')\n",
    "logistic_regression_model = joblib.load('./models/logistic_regression_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('./models/tfidf_vectorizer.pkl')\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def predict_sentiment(comment):\n",
    "    comment_tfidf = tfidf_vectorizer.transform([comment])\n",
    "    \n",
    "    svm_pred = svm_model.predict(comment_tfidf)[0]\n",
    "    rf_pred = random_forest_model.predict(comment_tfidf)[0]\n",
    "    reg_pred = logistic_regression_model.predict(comment_tfidf)[0]\n",
    "    \n",
    "    vader_score = analyzer.polarity_scores(comment)\n",
    "    if vader_score['compound'] >= 0.05:\n",
    "        vader_pred = 'positive'\n",
    "    elif vader_score['compound'] <= -0.05:\n",
    "        vader_pred = 'negative'\n",
    "    else:\n",
    "        vader_pred = 'neutral'\n",
    "    \n",
    "    return {\n",
    "        'SVM Prediction': svm_pred,\n",
    "        'Random Forest Prediction': rf_pred,\n",
    "        'Logistic Regression Prediction': reg_pred,\n",
    "        'VADER Prediction': vader_pred\n",
    "    }\n",
    "\n",
    "# input\n",
    "comment = input(\"Please enter a comment here: \")\n",
    "predictions = predict_sentiment(comment)\n",
    "\n",
    "display(Markdown(\"\\n**Sentiment Analysis Predictions:**\"))\n",
    "for method, pred in predictions.items():\n",
    "    print(f\"{method}: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
